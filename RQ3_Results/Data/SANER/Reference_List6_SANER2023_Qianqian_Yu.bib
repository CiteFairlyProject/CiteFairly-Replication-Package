@misc{ref1,
  author = {David E. Shaw and William Swartout and C. Cordell Green},
  title = {Inferring LISP programs from examples},
  year = {1975}
}

@misc{ref2,
  author = {Phillip D. Summers},
  title = {A Methodology for LISP Program Construction from Examples},
  year = {1977}
}

@misc{ref3,
  author = {David Harel and H. Lachover and A. Naamad and Amir Pnueli and M. Politi and R. W. Sherman and Aharon Shtull-Trauring and Mark Trakhtenbrot},
  title = {STATEMATE: a working environment for the development of complex reactive systems},
  year = {1990}
}

@misc{ref4,
  author = {Michael W. Whalen and Mats P. E. Heimdahl},
  title = {An approach to automatic code generation for safety-critical systems},
  year = {2003}
}

@misc{ref5,
  author = {Michael W. Whalen},
  title = {High-integrity code generation for state-based formalisms},
  year = {2000}
}

@misc{ref6,
  author = {Min Joon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},
  title = {Bidirectional Attention Flow for Machine Comprehension},
  year = {2016}
}

@misc{ref7,
  author = {Rahul Gupta and Soham Pal and Aditya Kanade and Shirish Shevade},
  title = {DeepFix: Fixing Common C Language Errors by Deep Learning},
  year = {2017}
}

@misc{ref8,
  author = {Abigail See and Peter J. Liu and Christopher D. Manning},
  title = {Get To The Point: Summarization with Pointer-Generator Networks},
  year = {2017}
}

@misc{ref9,
  author = {Jie Hu and Li Shen and Gang Sun},
  title = {Squeeze-and-Excitation Networks},
  year = {2018}
}

@misc{ref10,
  author = {Rahul Gupta and Aditya Kanade and Shirish Shevade},
  title = {Deep Reinforcement Learning for Programming Language Correction},
  year = {2018}
}

@misc{ref11,
  author = {Han Zhang and Ian Goodfellow and Dimitris Metaxas and Augustus Odena},
  title = {Self-Attention Generative Adversarial Networks},
  year = {2018}
}

@misc{ref12,
  author = {Michele Tufano and Cody Watson and Gabriele Bavota and Massimiliano Di Penta and Martin White and Denys Poshyvanyk},
  title = {An empirical investigation into learning bug-fixing patches in the wild via neural machine translation},
  year = {2018}
}

@misc{ref13,
  author = {Pengcheng Yin and Graham Neubig},
  title = {TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation},
  year = {2018}
}

@misc{ref14,
  author = {Anatolii Stehnii},
  title = {Generation of code from text description with syntactic parsing and Tree2Tree model},
  year = {2018}
}

@misc{ref15,
  author = {Xiang Li and Wenhai Wang and Xiaolin Hu and Jian Yang},
  title = {Selective Kernel Networks},
  year = {2019}
}

@misc{ref16,
  author = {Jun Fu and Jing Liu and Haijie Tian and Yong Li and Yongjun Bao and Zhiwei Fang and Hanqing Lu},
  title = {Dual Attention Network for Scene Segmentation},
  year = {2019}
}

@misc{ref17,
  author = {Hossein Hajipour and Apratim Bhattacharyya and Mario Fritz},
  title = {SampleFix: Learning to Correct Programs by Sampling Diverse Fixes},
  year = {2019}
}

@misc{ref18,
  author = {Maxim Rabinovich and Mitchell Stern and Dan Klein},
  title = {Abstract Syntax Networks for Code Generation and Semantic Parsing},
  year = {2017}
}

@misc{ref19,
  author = {Xiaolong Wang and Ross Girshick and Abhinav Gupta and Kaiming He},
  title = {Non-local Neural Networks},
  year = {2018}
}

@misc{ref20,
  author = {Guillaume Klein and Yoon Kim and Yuntian Deng and Jean Sénellart and Alexander M. Rush},
  title = {OpenNMT: Open-Source Toolkit for Neural Machine Translation},
  year = {2017}
}

@misc{ref21,
  author = {Li Dong and Mirella Lapata},
  title = {Coarse-to-Fine Decoding for Neural Semantic Parsing},
  year = {2018}
}

@misc{ref22,
  author = {Pengcheng Yin and Graham Neubig},
  title = {A Syntactic Neural Model for General-Purpose Code Generation},
  year = {2017}
}

@misc{ref23,
  author = {Zeyu Sun and Qihao Zhu and Lili Mou and Yingfei Xiong and Ge Li and Lu Zhang},
  title = {A Grammar-Based Structural CNN Decoder for Code Generation},
  year = {2019}
}

@misc{ref24,
  author = {Ling Wang and Phil Blunsom and Edward Grefenstette and Karl Moritz Hermann and Tomáš Kočiský and Fumin Wang and Andrew Senior},
  title = {Latent Predictor Networks for Code Generation},
  year = {2016}
}

@misc{ref25,
  author = {Ali Mesbah and Andrew Rice and Emily Johnston and Nick Glorioso and Edward Aftandilian},
  title = {DeepDelta: learning to repair compilation errors},
  year = {2019}
}

@misc{ref26,
  author = {Sumith Kulal and Panupong Pasupat and Kartik Chandra and Mina Lee and Oded Padon and Alex Aiken and Percy Liang},
  title = {SPoC: Search-based Pseudocode to Code},
  year = {2019}
}

@misc{ref27,
  author = {Zeyu Sun and Qihao Zhu and Yingfei Xiong and Yican Sun and Lili Mou and Lu Zhang},
  title = {TreeGen: A Tree-Based Transformer Architecture for Code Generation},
  year = {2020}
}

@misc{ref28,
  author = {Yi Tay and Dara Bahri and Donald Metzler and Da-Cheng Juan and Zhe Zhao and Che Zheng},
  title = {Synthesizer: Rethinking Self-Attention in Transformer Models},
  year = {2020}
}

@misc{ref29,
  author = {Michihiro Yasunaga and Percy Liang},
  title = {Graph-based, Self-Supervised Program Repair from Diagnostic Feedback},
  year = {2020}
}

@misc{ref30,
  author = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Fang Han and Hao Ma},
  title = {Linformer: Self-Attention with Linear Complexity},
  year = {2020}
}

@misc{ref31,
  author = {Bailin Wang and Richard Shin and Xiaodong Liu and Oleksandr Polozov and Matthew Richardson},
  title = {RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers},
  year = {2020}
}

@misc{ref32,
  author = {Colin Clement and Dawn Drain and Jonathan Timcheck and A. Svyatkovskiy and Neel Sundaresan},
  title = {PyMT5: multi-mode translation of natural language and Python code with transformers},
  year = {2020}
}

@misc{ref33,
  author = {Alexey Svyatkovskiy and Shao Kun Deng and Sheng‐Yu Fu and Neel Sundaresan},
  title = {IntelliCode compose: code generation using transformer},
  year = {2020}
}

@misc{ref34,
  author = {Xiao Yang},
  title = {An Overview of the Attention Mechanisms in Computer Vision},
  year = {2020}
}

@misc{ref35,
  author = {Christopher D. Wickens},
  title = {Attention: Theory, Principles, Models and Applications},
  year = {2021}
}

@misc{ref36,
  author = {Berkay Berabi and Jingxuan He and Veselin Raychev and Martin Vechev},
  title = {TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer},
  year = {2021}
}

@misc{ref37,
  author = {Michihiro Yasunaga and Percy Liang},
  title = {Break-It-Fix-It: Unsupervised Learning for Program Repair},
  year = {2021}
}

@misc{ref38,
  author = {Yu Tang and Long Zhou and Ambrosio Blanco and Shujie Liu and Furu Wei and Ming Zhou and Muyun Yang},
  title = {Grammar-Based Patches Generation for Automated Program Repair},
  year = {2021}
}

@misc{ref39,
  author = {Jiaqi Bai and Long Zhou and Ambrosio Blanco and Shujie Liu and Furu Wei and Ming Zhou and Zhoujun Li},
  title = {Jointly Learning to Repair Code and Generate Commit Message},
  year = {2021}
}

@misc{ref40,
  author = {Sneha Chaudhari and Varun Mithal and Gungor Polatkan and Rohan Ramanath},
  title = {An Attentive Survey of Attention Models},
  year = {2021}
}

@misc{ref41,
  author = {Meng-Hao Guo and Tian-Xing Xu and Jiangjiang Liu and Zheng-Ning Liu and Peng-Tao Jiang and Tai‐Jiang Mu and Song–Hai Zhang and Ralph R. Martin and Ming‐Ming Cheng and Shi‐Min Hu},
  title = {Attention mechanisms in computer vision: A survey},
  year = {2022}
}

@misc{ref42,
  author = {Guang Yang and Xiang Chen and Yanlin Zhou and Chi Yu},
  title = {DualSC: Automatic Generation and Summarization of Shellcode via Transformer and Dual Learning},
  year = {2022}
}

@misc{ref43,
  author = {Ying Zhang and Ya Xiao and Md Mahir Asef Kabir and Danfeng Yao and Na Meng},
  title = {Example-based vulnerability detection and repair in Java code},
  year = {2022}
}

@misc{ref44,
  author = {Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
  title = {FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  year = {2022}
}

@misc{ref45,
  author = {Anonymous Anonymous},
  title = {SYNFIX: Automatically Fixing Syntax Errors using Compiler Diagnostics},
  year = {2021}
}

@misc{ref46,
  author = {Wenkang Zhong and Chuanyi Li and Jidong Ge and Bin Luo},
  title = {Neural Program Repair : Systems, Challenges and Solutions},
  year = {2022}
}

@misc{ref47,
  author = {Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Píetro Lió and Yoshua Bengio},
  title = {Graph Attention Networks},
  year = {2017}
}

@misc{ref48,
  author = {Yujia Li and David Choi and Jun‐Young Chung and Nate Kushman and Julian Schrittwieser and Rémi Leblond and Tom Eccles and James Keeling and Felix Gimeno and Agustin Dal Lago and Thomas Hubert and Peter Choy and Cyprien de Masson d’Autume and I. Babuschkin and Xinyun Chen and Po-Sen Huang and Johannes Welbl and Sven Gowal and Alexey V. Cherepanov and James Molloy and Daniel J. Mankowitz and Esme Sutherland Robson and Pushmeet Kohli and Nando de Freitas and Koray Kavukcuoglu and Oriol Vinyals},
  title = {Competition-level code generation with AlphaCode},
  year = {2022}
}

@misc{ref49,
  author = {Xueyang Li and Shangqing Liu and Ruitao Feng and Guozhu Meng and Xiaofei Xie and Kai Chen and Yang Liu},
  title = {TransRepair: Context-aware Program Repair for Compilation Errors},
  year = {2022}
}

@misc{ref50,
  author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Łukasz Kaiser and Illia Polosukhin},
  title = {Attention Is All You Need},
  year = {2017}
}

