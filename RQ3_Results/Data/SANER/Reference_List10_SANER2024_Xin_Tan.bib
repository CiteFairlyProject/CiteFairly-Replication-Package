@misc{ref1,
  author = {Patricia Fusch and Lawrence Ness},
  title = {Are We There Yet? Data Saturation in Qualitative Research},
  year = {2015}
}

@misc{ref2,
  author = {Daniela S. Cruzes and T. Dyba},
  title = {Recommended Steps for Thematic Synthesis in Software Engineering},
  year = {2011}
}

@misc{ref3,
  author = {Barry E. Storer and Choongrak Kim},
  title = {Exact Properties of Some Exact Test Statistics for Comparing Two Binomial Proportions},
  year = {1990}
}

@misc{ref4,
  author = {Christoffer Rosen and Emad Shihab},
  title = {What are mobile developers asking about? A large scale study using stack overflow},
  year = {2015}
}

@misc{ref5,
  author = {Patrick Biernacki and Dan Waldorf},
  title = {Snowball Sampling: Problems and Techniques of Chain Referral Sampling},
  year = {1981}
}

@misc{ref6,
  author = {Carl Ratner},
  title = {Subjectivity and Objectivity in Qualitative Methodology},
  year = {2002}
}

@misc{ref7,
  author = {Miltiadis Allamanis and Charles Sutton},
  title = {Why, when, and what: Analyzing Stack Overflow questions by topic, type, and code},
  year = {2013}
}

@misc{ref8,
  author = {Luca Ponzanelli and Andrea Mocci and Alberto Bacchelli and Michele Lanza and David A. Fullerton},
  title = {Improving Low Quality Stack Overflow Post Detection},
  year = {2014}
}

@misc{ref9,
  author = {Christoph Treude and Martin P. Robillard},
  title = {Augmenting API documentation with insights from stack overflow},
  year = {2016}
}

@misc{ref10,
  author = {Yasemin Acar and Michael Backes and Sascha Fahl and Doowon Kim and Michelle L. Mazurek and Christian Stransky},
  title = {You Get Where You're Looking for: The Impact of Information Sources on Code Security},
  year = {2016}
}

@misc{ref11,
  author = {Xin-Li Yang and David Lo and Xin Xia and Zhi-Yuan Wan and Jian-Ling Sun},
  title = {What Security Questions Do Developers Ask? A Large-Scale Study of Stack Overflow Posts},
  year = {2016}
}

@misc{ref12,
  author = {Pavneet Singh Kochhar},
  title = {Mining testing questions on stack overflow},
  year = {2016}
}

@misc{ref13,
  author = {Kostadin Cholakov and van Gerardus Noord and Valia Kordoni and Yueheng Zhang},
  title = {Proceedings of the International Conference Recent Advances in Natural Language Processing 2011},
  year = {2011}
}

@misc{ref14,
  author = {Yang Li and Tao Yang},
  title = {Word Embedding for Understanding Natural Language: A Survey},
  year = {2017}
}

@misc{ref15,
  author = {Achraf Oussidi and Azeddine Elhassouny},
  title = {Deep generative models: Survey},
  year = {2018}
}

@misc{ref16,
  author = {Awdren Fontão and Bruno Ábia and Igor Wiese and Bernardo José da Silva Estácio and Marcelo Ricardo Quinta and Rodrigo Pereira dos Santos and Arilo Claudio Dias‐Neto},
  title = {Supporting governance of mobile application developers from mining and analyzing technical questions in stack overflow},
  year = {2018}
}

@misc{ref17,
  author = {Jacob Devlin and Ming‐Wei Chang and Kenton Lee and Kristina Toutanova},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year = {2018}
}

@misc{ref18,
  author = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel Bowman},
  title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  year = {2018}
}

@misc{ref19,
  author = {Haoxiang Zhang and Shaowei Wang and Tse-Hsun Chen and Ying Zou and Ahmed E. Hassan},
  title = {An Empirical Study of Obsolete Answers on Stack Overflow},
  year = {2019}
}

@misc{ref20,
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  year = {2019}
}

@misc{ref21,
  author = {Ian Tenney and Dipanjan Das and Ellie Pavlick},
  title = {BERT Rediscovers the Classical NLP Pipeline},
  year = {2019}
}

@misc{ref22,
  author = {Mehdi Bagherzadeh and Raffi Khatchadourian},
  title = {Going big: a large-scale study on what big data developers ask},
  year = {2019}
}

@misc{ref23,
  author = {Felix Fischer and Konstantin Böttinger and Huang Xiao and Christian Stransky and Yasemin Acar and Michael Backes and Sascha Fahl},
  title = {Stack Overflow Considered Harmful? The Impact of Copy&amp;Paste on Android Application Security},
  year = {2017}
}

@misc{ref24,
  author = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  year = {2019}
}

@misc{ref25,
  author = {Nitish Shirish Keskar and Bryan McCann and Lav R. Varshney and Caiming Xiong and Richard Socher},
  title = {CTRL: A Conditional Transformer Language Model for Controllable Generation},
  year = {2019}
}

@misc{ref26,
  author = {Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  title = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  year = {2019}
}

@misc{ref27,
  author = {Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clément Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Jamie Brew},
  title = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  year = {2019}
}

@misc{ref28,
  author = {Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
  title = {ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  year = {2019}
}

@misc{ref29,
  author = {Guillermo Blanco and Roi Pérez-López and Florentino Fdez‐Riverola and Anália Lourenço},
  title = {Understanding the social evolution of the Java community in Stack Overflow: A 10-year study of developer interactions},
  year = {2019}
}

@misc{ref30,
  author = {Wonjin Yoon and Jinhyuk Lee and Donghyeon Kim and Minbyul Jeong and Jaewoo Kang},
  title = {Pre-trained Language Model for Biomedical Question Answering},
  year = {2020}
}

@misc{ref31,
  author = {Xiao Liu and Fanjin Zhang and Zhenyu Hou and Mian Li and Zhaoyu Wang and Jing Zhang and Jie Tang},
  title = {Self-supervised Learning: Generative or Contrastive},
  year = {2021}
}

@misc{ref32,
  author = {Ahmad Abdellatif and Diego Elias Costa and Khaled Badran and Rabe Abdalkareem and Emad Shihab},
  title = {Challenges in Chatbot Development},
  year = {2020}
}

@misc{ref33,
  author = {Zhenpeng Chen and Yanbin Cao and Yuanqiang Liu and Haoyu Wang and Tao Xie and Xuanzhe Liu},
  title = {A comprehensive study on challenges in deploying deep learning based software},
  year = {2020}
}

@misc{ref34,
  author = {Zhenpeng Chen and Huihan Yao and Yiling Lou and Yanbin Cao and Yuanqiang Liu and Haoyu Wang and Xuanzhe Liu},
  title = {An Empirical Study on Deployment Faults of Deep Learning Based Mobile Applications},
  year = {2021}
}

@misc{ref35,
  author = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Pondé de Oliveira Pinto and Jared Kaplan and Harrison Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Łukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth A. Barnes and Ariel Herbert-Voss and William H. Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and I. Babuschkin and Suchir Balaji and Shantanu Jain and William S. Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Joshua Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew M. Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  title = {Evaluating Large Language Models Trained on Code},
  year = {2021}
}

@misc{ref36,
  author = {Xu Han and Zhengyan Zhang and Ning Ding and Yuxian Gu and Xiao Liu and Yuqi Huo and Jiezhong Qiu and Yuan Yao and Ao Zhang and Liang Zhang and Wentao Han and Minlie Huang and Qin Jin and Yanyan Lan and Yang Liu and Zhiyuan Liu and Zhiwu Lu and Xipeng Qiu and Ruihua Song and Jie Tang and Ji-Rong Wen and Jinhui Yuan and Wayne Xin Zhao and Jun Zhu},
  title = {Pre-trained models: Past, present and future},
  year = {2021}
}

@misc{ref37,
  author = {Jian Yang and Gang Xiao and Yu-Long Shen and Wei Jiang and Xinyu Hu and Ying Zhang and Jinghui Peng},
  title = {A Survey of Knowledge Enhanced Pre-trained Models},
  year = {2021}
}

@misc{ref38,
  author = {Henghui Zhao and Yanhui Li and Fanwei Liu and Xiaoyuan Xie and Chen Lin},
  title = {State and tendency: an empirical study of deep learning question&amp;answer topics on Stack Overflow},
  year = {2021}
}

@misc{ref39,
  author = {Anjan Karmakar and Romain Robbes},
  title = {What do pre-trained code models know about code?},
  year = {2021}
}

@misc{ref40,
  author = {Mubin Ul Haque and Leonardo Horn Iwaya and Muhammad Ali Babar},
  title = {Challenges in Docker Development},
  year = {2020}
}

@misc{ref41,
  author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  year = {2019}
}

@misc{ref42,
  author = {T. B. Brown and Benjamin F. Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey C.S. Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric J. Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack A. Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  title = {Language Models are Few-Shot Learners},
  year = {2020}
}

@misc{ref43,
  author = {Haifeng Wang and Jiwei Li and Hua Wu and Eduard Hovy and Yu Sun},
  title = {Pre-Trained Language Models and Their Applications},
  year = {2022}
}

@misc{ref44,
  author = {Bonan Min and Hayley Ross and Elior Sulem and Amir Pouran Ben Veyseh and Thien Huu Nguyen and Oscar Sainz and Eneko Agirre and Ilana Heintz and Dan Roth},
  title = {Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey},
  year = {2023}
}

@misc{ref45,
  author = {Chao Wang and Zhenpeng Chen and Minghui Zhou},
  title = {AutoML from Software Engineering Perspective: Landscapes and Challenges},
  year = {2023}
}

@misc{ref46,
  author = {MA Jinlin CHEN Deguang},
  title = {Review of Pre-training Techniques for Natural Language Processing},
  year = {2021}
}

@misc{ref47,
  author = {Mohamad Ballout and Ulf Krumnack and Gunther Heidemann and Kai‐Uwe Kühnberger},
  title = {Opening the Black Box: Analyzing Attention Weights and Hidden States in Pre-trained Language Models for Non-language Tasks},
  year = {2023}
}

@misc{ref48,
  author = {},
  title = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
  year = {2024}
}

@misc{ref49,
  author = {Ce Zhou and Qian Li and Chen Li and Jun Yu and Yixin Liu and Guangjing Wang and Kai Zhang and Cheng Ji and Qiben Yan and Lifang He and Hao Peng and Jianxin Li and Jia Wu and Ziwei Liu and Pengtao Xie and Caiming Xiong and Jian Pei and Philip S. Yu and Lichao Sun},
  title = {A comprehensive survey on pretrained foundation models: a history from BERT to ChatGPT},
  year = {2024}
}

