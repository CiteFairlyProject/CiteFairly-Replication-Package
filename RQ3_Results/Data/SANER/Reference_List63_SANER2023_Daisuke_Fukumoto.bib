@misc{ref1,
  author = {V.I. Levenshtein},
  title = {Binary codes capable of correcting deletions, insertions, and reversals},
  year = {1966}
}

@misc{ref2,
  author = {Felix A. Gers and J. Schmidhuber and Fred Cummins},
  title = {Learning to forget: continual prediction with LSTM},
  year = {1999}
}

@misc{ref3,
  author = {Sven Amann and Sebastian Proksch and Sarah Nadi and Mira Mezini},
  title = {A Study of Visual Studio Usage in Practice},
  year = {2016}
}

@misc{ref4,
  author = {Shane McIntosh and Yasutaka Kamei},
  title = {Are Fix-Inducing Changes a Moving Target? A Longitudinal Case Study of Just-In-Time Defect Prediction},
  year = {2017}
}

@misc{ref5,
  author = {Chenhui Chu and Rui Wang},
  title = {A Survey of Domain Adaptation for Neural Machine Translation},
  year = {2018}
}

@misc{ref6,
  author = {Jacob Devlin and Ming‐Wei Chang and Kenton Lee and Kristina Toutanova},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year = {2018}
}

@misc{ref7,
  author = {Rafael-Michael Karampatsis and Charles Sutton},
  title = {Maybe Deep Neural Networks are the Best Choice for Modeling Source Code},
  year = {2019}
}

@misc{ref8,
  author = {Zhangyin Feng and Daya Guo and Duyu Tang and Nan Duan and Xiaocheng Feng and Ming Gong and Linjun Shou and Bing Qin and Ting Liu and Daxin Jiang and Ming Zhou},
  title = {CodeBERT: A Pre-Trained Model for Programming and Natural Languages},
  year = {2020}
}

@misc{ref9,
  author = {Alexey Svyatkovskiy and Shao Kun Deng and Sheng‐Yu Fu and Neel Sundaresan},
  title = {IntelliCode compose: code generation using transformer},
  year = {2020}
}

@misc{ref10,
  author = {Antonio Mastropaolo and Simone Scalabrino and Nathan Cooper and David N. Palacio and Denys Poshyvanyk and Rocco Oliveto and Gabriele Bavota},
  title = {Studying the Usage of Text-To-Text Transfer Transformer to Support Code-Related Tasks},
  year = {2021}
}

@misc{ref11,
  author = {Seohyun Kim and Jinman Zhao and Yuchi Tian and Satish Chandra},
  title = {Code Prediction by Feeding Trees to Transformers},
  year = {2021}
}

@misc{ref12,
  author = {Ozren Dabić and Emad Aghajani and Gabriele Bavota},
  title = {Sampling Projects in GitHub for MSR Studies},
  year = {2021}
}

@misc{ref13,
  author = {Yue Wang and Weishi Wang and Shafiq Joty and Steven C. H. Hoi},
  title = {CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation},
  year = {2021}
}

@misc{ref14,
  author = {Laura Pérez-Mayos and Miguel Ballesteros and Leo Wanner},
  title = {How much pretraining data do language models need to learn syntax?},
  year = {2021}
}

@misc{ref15,
  author = {Matteo Ciniselli and Nathan Cooper and Luca Pascarella and Antonio Mastropaolo and Emad Aghajani and Denys Poshyvanyk and Massimiliano Di Penta and Gabriele Bavota},
  title = {An Empirical Study on the Usage of Transformer Models for Code Completion},
  year = {2021}
}

@misc{ref16,
  author = {Yu Zhou and Juanjuan Shen and Xiaoqing Zhang and Wenhua Yang and Tingting Han and Taolue Chen},
  title = {Automatic source code summarization with graph attention networks},
  year = {2022}
}

@misc{ref17,
  author = {Madhab Sharma and Tapas Kumar Mishra and Arun Kumar},
  title = {Source code auto-completion using various deep learning models under limited computing resources},
  year = {2022}
}

@misc{ref18,
  author = {Alberto Bacchelli and Christian Bird},
  title = {Expectations, outcomes, and challenges of modern code review},
  year = {2013}
}

@misc{ref19,
  author = {Pascal Roos},
  title = {Fast and Precise Statistical Code Completion},
  year = {2015}
}

@misc{ref20,
  author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  year = {2019}
}

@misc{ref21,
  author = {Hamel Husain and Ho-Hsiang Wu and Tiferet Gazit and Miltiadis Allamanis and Marc Brockschmidt},
  title = {CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},
  year = {2019}
}

