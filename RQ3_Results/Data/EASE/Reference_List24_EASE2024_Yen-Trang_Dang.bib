@misc{ref1,
  author = {Yukun Zhu and Ryan Kiros and Rich Zemel and Ruslan Salakhutdinov and Raquel Urtasun and Antonio Torralba and Sanja Fidler},
  title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},
  year = {2015}
}

@misc{ref2,
  author = {Xin Xia and David Lo and Xinyu Wang and Bo Zhou},
  title = {Tag recommendation in software information sites},
  year = {2013}
}

@misc{ref3,
  author = {Christoph Treude and Margaret‐Anne Storey},
  title = {How tagging helps bridge the gap between social and technical aspects in software development},
  year = {2009}
}

@misc{ref4,
  author = {Laura Dabbish and Colleen Stuart and Jason Tsay and Jim Herbsleb},
  title = {Social coding in GitHub},
  year = {2012}
}

@misc{ref5,
  author = {Christoph Treude and Margaret‐Anne Storey},
  title = {Work Item Tagging: Communicating Concerns in Collaborative Software Development},
  year = {2010}
}

@misc{ref6,
  author = {Jason Tsay and Laura Dabbish and James D. Herbsleb},
  title = {Influence of social and technical factors for evaluating contribution in GitHub},
  year = {2014}
}

@misc{ref7,
  author = {Maria Christakis and Christian Bird},
  title = {What developers want and need from program analysis: an empirical study},
  year = {2016}
}

@misc{ref8,
  author = {Abhishek Sharma and Ferdian Thung and Pavneet Singh Kochhar and Agus Sulistya and David Lo},
  title = {Cataloging GitHub Repositories},
  year = {2017}
}

@misc{ref9,
  author = {Shaowei Wang and David Lo and Bogdan Vasilescu and Alexander Serebrenik},
  title = {EnTagRec ++: An enhanced tag recommendation system for software information sites},
  year = {2017}
}

@misc{ref10,
  author = {Caitlin Sadowski and Edward Aftandilian and Alex Eagle and Liam Miller-Cushon and Ciera Jaspan},
  title = {Lessons from building static analysis tools at Google},
  year = {2018}
}

@misc{ref11,
  author = {Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
  title = {Focal Loss for Dense Object Detection},
  year = {2017}
}

@misc{ref12,
  author = {PedregosaFabian and VaroquauxGaël and GramfortAlexandre and MichelVincent and ThirionBertrand and GriselOlivier and BlondelMathieu and PrettenhoferPeter and WeissRon and DubourgVincent and VanderplasJake and PassosAlexandre and CournapeauDavid and BrucherMatthieu and PerrotMatthieu and DuchesnayÉdouard},
  title = {Scikit-learn: Machine Learning in Python},
  year = {2011}
}

@misc{ref13,
  author = {Claudio Di Sipio and Riccardo Rubei and Davide Di Ruscio and Phuong T. Nguyen},
  title = {A Multinomial Naïve Bayesian (MNB) Network to Automatically Recommend Topics for GitHub Repositories},
  year = {2020}
}

@misc{ref14,
  author = {Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Veselin Stoyanov and Luke Zettlemoyer},
  title = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  year = {2020}
}

@misc{ref15,
  author = {Juri Di Rocco and Davide Di Ruscio and Claudio Di Sipio and Phuong T. Nguyen and Riccardo Rubei},
  title = {TopFilter},
  year = {2020}
}

@misc{ref16,
  author = {Joel Mackenzie and Rodger Benham and Matthias Petri and Johanne R. Trippas and J. Shane Culpepper and Alistair Moffat},
  title = {CC-News-En},
  year = {2020}
}

@misc{ref17,
  author = {Ting Zhang and Bowen Xu and Ferdian Thung and Stefanus Agus Haryono and David Lo and Lingxiao Jiang},
  title = {Sentiment Analysis for Software Engineering: How Far Can Pre-trained Transformer Models Go?},
  year = {2020}
}

@misc{ref18,
  author = {Fang Liu and Ge Li and Yunfei Zhao and Zhi Jin},
  title = {Multi-task learning based pre-trained language model for code completion},
  year = {2020}
}

@misc{ref19,
  author = {Nilesh Gupta and Sakina Bohra and Yashoteja Prabhu and Saurabh Purohit and Manik Varma},
  title = {Generalized Zero-Shot Extreme Multi-label Learning},
  year = {2021}
}

@misc{ref20,
  author = {Davide Chicco and Matthijs J. Warrens and Giuseppe Jurman},
  title = {The Matthews Correlation Coefficient (MCC) is More Informative Than Cohen’s Kappa and Brier Score in Binary Classification Assessment},
  year = {2021}
}

@misc{ref21,
  author = {Maliheh Izadi and Abbas Heydarnoori and Georgios Gousios},
  title = {Topic recommendation for software repositories using multi-label classification algorithms},
  year = {2021}
}

@misc{ref22,
  author = {Deze Wang and Zhouyang Jia and Shanshan Li and Yue Yu and Yun Xiong and Wei Dong and Xiangke Liao},
  title = {Bridging pre-trained models and downstream tasks for source code understanding},
  year = {2022}
}

@misc{ref23,
  author = {Junda He and Bowen Xu and Zhou Yang and DongGyun Han and Chengran Yang and David Lo},
  title = {PTM4Tag},
  year = {2022}
}

@misc{ref24,
  author = {Grigorios Tsoumakas and Ioannis Katakis},
  title = {Multi-Label Classification},
  year = {2009}
}

@misc{ref25,
  author = {Chris Lewis and Zhongpeng Lin and Caitlin Sadowski and Xiaoyan Zhu and Rong Ou and E. James Whitehead},
  title = {Does bug prediction support human developers? Findings from a Google case study},
  year = {2013}
}

@misc{ref26,
  author = {Thanh Le-Cong and Hong Jin Kang and Truong Giang Nguyen and Stefanus Agus Haryono and David Lo and Xuan-Bach D. Le and Quyet Thang Huynh},
  title = {AutoPruner: transformer-based call graph pruning},
  year = {2022}
}

@misc{ref27,
  author = {Montassar Ben Messaoud and Asma Miladi and Ilyes Jenhani and Mohamed Wiem Mkaouer and Lobna Ghadhab},
  title = {Duplicate Bug Report Detection Using an Attention-Based Neural Language Model},
  year = {2022}
}

@misc{ref28,
  author = {Toufique Ahmed and Prémkumar Dévanbu},
  title = {Few-shot training LLMs for project-specific code-summarization},
  year = {2022}
}

@misc{ref29,
  author = {Xianchang Luo and Yinxing Xue and Zhenchang Xing and Jiamou Sun},
  title = {PRCBERT: Prompt Learning for Requirement Classification using BERT-based Pretrained Language Models},
  year = {2022}
}

@misc{ref30,
  author = {Qing Huang and Zhiqiang Yuan and Zhenchang Xing and Xiwei Xu and Liming Zhu and Qinghua Lu},
  title = {Prompt-tuned Code Language Model as a Neural Knowledge Base for Type Inference in Statically-Typed Partial Code},
  year = {2022}
}

@misc{ref31,
  author = {Ratnadira Widyasari and Zhipeng Zhao and Thanh Le Cong and Hong Jin Kang and David Lo},
  title = {Topic Recommendation for GitHub Repositories: How Far Can Extreme Multi-Label Learning Go?},
  year = {2023}
}

@misc{ref32,
  author = {Bonan Min and Hayley Ross and Elior Sulem and Amir Pouran Ben Veyseh and Thien Huu Nguyen and Oscar Sainz and Eneko Agirre and Ilana Heintz and Dan Roth},
  title = {Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey},
  year = {2023}
}

@misc{ref33,
  author = {Yunbo Lyu and Thanh Le-Cong and Hong Jin Kang and Ratnadira Widyasari and Zhipeng Zhao and Xuan-Bach D. Le and Ming Li and David Lo},
  title = {CHRONOS: Time-Aware Zero-Shot Identification of Libraries from Vulnerability Reports},
  year = {2023}
}

@misc{ref34,
  author = {Haoyu Gao and Christoph Treude and Mansooreh Zahedi},
  title = {Evaluating Transfer Learning for Simplifying GitHub READMEs},
  year = {2023}
}

@misc{ref35,
  author = {Bowen Xu and Thanh-Dat Nguyen and Thanh Le-Cong and Thong Hoang and Jiakun Liu and Kisub Kim and Gong Chen and Changan Niu and Chenyu Wang and Bach Le and David Lo},
  title = {Are We Ready to Embrace Generative AI for Software Q&amp;A?},
  year = {2023}
}

